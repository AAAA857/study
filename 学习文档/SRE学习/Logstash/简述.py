'''

#简述
 Logstash 是一个开源的数据搜索工具，可以接受来自不通的数据源，可以对数据做正规化、最后将数据输入到目标。

 # 特点
    1. 插件化
    2. 支持输入、正规化、输出

# 工作原理
    1. Logstash 接收分为三个阶段：
        1.1 输入
        1.2 过滤器
        1.3 输出

    # 输入
      通常指数据采集，可以来自于 file、redis、es、kafka、syslog 等等，
    # 过滤器
      通常对采集数据做正规化、正则匹配等，通常使用的过滤器包括：
        1. grok 解析和构造任意文本，grok目前是最佳的日志处理插件内置120种模式
        2. mutate 对事件字段执行一般转换如 重命名、删除、替换
        3. drop  完全删除事件
        4. geoip  添加有关地理位置信息
    # 输出
      通常为logstash最后阶段，将数据推送到目的端，同样支持如下：
        1. elasticsearch
        2. redis
        3. kafka
        4. file
        ....

    # 工作模型
       Logstash 每个阶段都是独立线程在工作，每个管道进程取出一批事件去做处理，通过消息队列方式做到多线程消息同步，
       通常保存在内存中（临时队列），如果意外关闭可能会导致数据丢失，因此可以考虑将数据保存在文件内（持久队列）。

    # 数据处理顺序
      通常Logstash是不保证数据的顺序一致性，但是可以在如下模式中调整顺序:
        1. 同一批次数据内做排序
        2. 多个数据源，对正在运行的数据做排序

      # 配置顺序配置方式
      logstash.yml：
        pipeline.ordered=auto|true|false
            auto 表示自动启动排序由服务完成
            true 表示强制开启，如果有多个采集插件将会阻止服务启动
            false 表示关闭排序 不能保证消息顺序性



'''